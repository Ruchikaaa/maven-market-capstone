{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06b4d856-c3d0-43ec-83b3-81f3c91f31e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## fact returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c517325-1166-4432-82d1-3002587b97c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, to_date\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"maven_uc.gold_dlt.fact_returns\",\n",
    "    comment=\"Fact table for returns\"\n",
    ")\n",
    "def fact_returns():\n",
    "    df = dlt.read(\"maven_uc.silver_dlt.returns_silver\")\n",
    "    return (\n",
    "        df\n",
    "        .select(\n",
    "            \"return_date\",\n",
    "            \"product_id\",\n",
    "            \"store_id\",\n",
    "            \"quantity\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea5f68d6-6a9e-418b-85d1-8f9c7d7a4ed4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## fact inventory events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b51a680-c3cc-44ad-be8a-6cb06c4031a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"maven_uc.gold_dlt.fact_inventory_events\",\n",
    "    comment=\"Fact table for inventory restock events\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_product\", \"product_id IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_store\", \"store_id IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_qty\", \"restock_qty >= 0\")\n",
    "def fact_inventory_events():\n",
    "    df = dlt.read(\"maven_uc.silver_dlt.inventory_events_silver\")\n",
    "    return (\n",
    "        df.select(\n",
    "            \"product_id\",\n",
    "            \"store_id\",\n",
    "            \"restock_qty\",\n",
    "            \"quantity_remaining\",\n",
    "            \"restock_date\",\n",
    "            \"event_ts\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da20ab16-862e-4cef-bf13-c5ab436bc633",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## fact orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2773831a-808e-4a23-a042-19bff50f5ef3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"maven_uc.gold_dlt.fact_order_events\",\n",
    "    comment=\"Fact table for order events\"\n",
    ")\n",
    "def fact_order_events():\n",
    "    df = dlt.read_stream(\"maven_uc.silver_dlt.orders_events_silver\")\n",
    "    return (\n",
    "        df.select(\n",
    "            \"order_id\",\n",
    "            \"customer_id\",\n",
    "            \"product_id\",\n",
    "            \"store_id\",\n",
    "            \"order_date\",\n",
    "            \"quantity\",\n",
    "            \"stock_date\",\n",
    "            \"payment_type\",\n",
    "            \"unit_price\",\n",
    "            \"order_ts\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a11e25f-8f7a-42d7-abdc-4d23db3b2502",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## fact sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2bcb6d3-0138-4982-84a4-c8497eafc3ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, lit, to_date, regexp_replace,concat\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"maven_uc.gold_dlt.fact_sales\",\n",
    "    comment=\"Unified sales records from online orders and in-store transactions.\"\n",
    ")\n",
    "def fact_sales():\n",
    "    # 1. Process Online Orders (Cleaning string-based unit_price)\n",
    "    orders_df = dlt.read(\"maven_uc.silver_dlt.orders_events_silver\").select(\n",
    "        col(\"order_id\"),\n",
    "        col(\"customer_id\"),\n",
    "        col(\"product_id\"),\n",
    "        col(\"store_id\"),\n",
    "        to_date(col(\"order_date\")).alias(\"sales_date\"),\n",
    "        col(\"quantity\").cast(\"int\"),\n",
    "        # Clean string: remove '$' or ',' then cast to double\n",
    "        regexp_replace(col(\"unit_price\"), \"[$,]\", \"\").cast(\"double\").alias(\"unit_price\"),\n",
    "        lit(\"ONLINE\").alias(\"sales_channel\")\n",
    "    ).withColumn(\"revenue\", col(\"quantity\") * col(\"unit_price\"))\n",
    "\n",
    "    # 2. Process In-Store Transactions\n",
    "    products_df = dlt.read(\"maven_uc.gold_dlt.dim_products\").select(\"product_id\", \"product_retail_price\")\n",
    "    stores_df = dlt.read(\"maven_uc.gold_dlt.dim_stores\").select(\"store_id\", \"region_id\")\n",
    "\n",
    "\n",
    "    \n",
    "    transactions_df = dlt.read(\"maven_uc.silver_dlt.transactions_silver\") \\\n",
    "        .join(products_df, \"product_id\", \"left\") \\\n",
    "        .select(\n",
    "            concat(lit(\"POS-\"), col(\"customer_id\"), lit(\"-\"), col(\"transaction_date\")).alias(\"order_id\"),\n",
    "            col(\"customer_id\"),\n",
    "            col(\"product_id\"),\n",
    "            col(\"store_id\"),\n",
    "            to_date(col(\"transaction_date\")).alias(\"sales_date\"),\n",
    "            col(\"quantity\").cast(\"int\"),\n",
    "            col(\"product_retail_price\").cast(\"double\").alias(\"unit_price\"),\n",
    "            lit(\"POS\").alias(\"sales_channel\")\n",
    "        ).withColumn(\"revenue\", col(\"quantity\") * col(\"unit_price\"))\n",
    "\n",
    "    combined_df = orders_df.unionByName(transactions_df)\n",
    "    \n",
    "    return combined_df.join(stores_df, \"store_id\", \"left\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dlt_gold_facts",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
